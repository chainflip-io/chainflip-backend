use std::collections::{BTreeSet, HashMap};
use std::sync::Arc;

use crate::multisig::client::{self, KeygenResultInfo};
use crate::{common::format_iterator, logging::KEYGEN_REJECTED_INCOMPATIBLE};

use client::{
    common::{
        broadcast::{verify_broadcasts, BroadcastStage, BroadcastStageProcessor, DataToSend},
        CeremonyCommon, KeygenResult, StageResult,
    },
    keygen, ThresholdParameters,
};

use crate::multisig::crypto::{BigInt, BigIntConverter, KeyShare};

use keygen::{
    keygen_data::{
        BlameResponse6, Comm1, Complaints4, KeygenData, SecretShare3, VerifyComm2,
        VerifyComplaints5,
    },
    keygen_frost::{
        derive_aggregate_pubkey, derive_local_pubkeys_for_parties, generate_shares_and_commitment,
        validate_commitments, verify_share, DKGCommitment, DKGUnverifiedCommitment, IncomingShares,
        OutgoingShares,
    },
};

use super::keygen_frost::ShamirShare;
use super::KeygenOptions;
use super::{keygen_data::VerifyBlameResponses7, HashContext};

/// Stage 1: Sample a secret, generate sharing polynomial coefficients for it
/// and a ZKP of the secret. Broadcast commitments to the coefficients and the ZKP.
pub struct AwaitCommitments1 {
    common: CeremonyCommon,
    own_commitment: DKGUnverifiedCommitment,
    /// Shares generated by us for other parties (secret)
    shares: OutgoingShares,
    keygen_options: KeygenOptions,
    /// Context to prevent replay attacks
    context: HashContext,
}

impl AwaitCommitments1 {
    pub fn new(
        mut common: CeremonyCommon,
        keygen_options: KeygenOptions,
        context: HashContext,
    ) -> Self {
        let params = ThresholdParameters::from_share_count(common.all_idxs.len());

        let (shares, own_commitment) =
            generate_shares_and_commitment(&mut common.rng, &context, common.own_idx, params);

        AwaitCommitments1 {
            common,
            own_commitment,
            shares,
            keygen_options,
            context,
        }
    }
}

derive_display_as_type_name!(AwaitCommitments1);

impl BroadcastStageProcessor<KeygenData, KeygenResultInfo> for AwaitCommitments1 {
    type Message = Comm1;

    fn init(&mut self) -> DataToSend<Self::Message> {
        DataToSend::Broadcast(self.own_commitment.clone())
    }

    fn should_delay(&self, m: &KeygenData) -> bool {
        matches!(m, KeygenData::Verify2(_))
    }

    fn process(
        self,
        messages: HashMap<usize, Option<Self::Message>>,
    ) -> StageResult<KeygenData, KeygenResultInfo> {
        // We have received commitments from everyone, for now just need to
        // go through another round to verify consistent broadcasts

        let processor = VerifyCommitmentsBroadcast2 {
            common: self.common.clone(),
            commitments: messages,
            shares_to_send: self.shares,
            keygen_options: self.keygen_options,
            context: self.context,
        };

        let stage = BroadcastStage::new(processor, self.common);

        StageResult::NextStage(Box::new(stage))
    }
}

/// Stage 2: verify broadcasts of Stage 1 data
struct VerifyCommitmentsBroadcast2 {
    common: CeremonyCommon,
    commitments: HashMap<usize, Option<Comm1>>,
    shares_to_send: OutgoingShares,
    keygen_options: KeygenOptions,
    context: HashContext,
}

derive_display_as_type_name!(VerifyCommitmentsBroadcast2);

/// Check if the public key's x coordinate is smaller than "half secp256k1's order",
/// which is a requirement imposed by the Key Manager contract
pub fn is_contract_compatible(pk: &secp256k1::PublicKey) -> bool {
    let pubkey = cf_chains::eth::AggKey::from(pk);

    let x = BigInt::from_bytes(&pubkey.pub_key_x);
    let half_order = BigInt::from_bytes(&secp256k1::constants::CURVE_ORDER) / 2 + 1;

    x < half_order
}

impl BroadcastStageProcessor<KeygenData, KeygenResultInfo> for VerifyCommitmentsBroadcast2 {
    type Message = VerifyComm2;

    fn init(&mut self) -> DataToSend<Self::Message> {
        let data = self.commitments.clone();

        DataToSend::Broadcast(VerifyComm2 { data })
    }

    fn should_delay(&self, m: &KeygenData) -> bool {
        matches!(m, KeygenData::SecretShares3(_))
    }

    fn process(
        self,
        messages: std::collections::HashMap<usize, Option<Self::Message>>,
    ) -> StageResult<KeygenData, KeygenResultInfo> {
        let commitments = match verify_broadcasts(messages, &self.common.logger) {
            Ok(comms) => comms,
            Err(blamed_parties) => {
                return StageResult::Error(
                    blamed_parties,
                    anyhow::Error::msg("Inconsistent broadcast of initial commitments"),
                )
            }
        };

        let commitments = match validate_commitments(commitments, &self.context) {
            Ok(comms) => comms,
            Err(blamed_parties) => {
                return StageResult::Error(
                    blamed_parties,
                    anyhow::Error::msg("Invalid initial commitments"),
                )
            }
        };

        slog::debug!(
            self.common.logger,
            "Initial commitments have been correctly broadcast"
        );

        // At this point we know everyone's commitments, which can already be
        // used to derive the resulting aggregate public key. Before proceeding
        // with the ceremony, we need to make sure that the key is compatible
        // with the Key Manager contract, aborting if it isn't.

        let agg_pubkey = derive_aggregate_pubkey(&commitments);

        // Note that we skip this check in tests as it would make them
        // non-deterministic (in the future, we could address this by
        // making the signer use deterministic randomness everywhere)
        if !self.keygen_options.low_pubkey_only || is_contract_compatible(&agg_pubkey.get_element())
        {
            let processor = SecretSharesStage3 {
                common: self.common.clone(),
                commitments,
                shares: self.shares_to_send,
            };

            let stage = BroadcastStage::new(processor, self.common);

            StageResult::NextStage(Box::new(stage))
        } else {
            slog::debug!(
                self.common.logger,
                #KEYGEN_REJECTED_INCOMPATIBLE,
                "The key is not contract compatible, aborting..."
            );
            // It is nobody's fault that the key is not compatible,
            // so we abort with an empty list of responsible nodes
            // to let the State Chain restart the ceremony
            StageResult::Error(
                vec![],
                anyhow::Error::msg("The key is not contract compatible"),
            )
        }
    }
}

/// Stage 3: distribute (distinct) secret shares of our secret to each party
struct SecretSharesStage3 {
    common: CeremonyCommon,
    // commitments (verified to have been broadcast correctly)
    commitments: HashMap<usize, DKGCommitment>,
    shares: OutgoingShares,
}

derive_display_as_type_name!(SecretSharesStage3);

impl BroadcastStageProcessor<KeygenData, KeygenResultInfo> for SecretSharesStage3 {
    type Message = SecretShare3;

    fn init(&mut self) -> DataToSend<Self::Message> {
        // With everyone committed to their secrets and sharing polynomial coefficients
        // we can now send the *distinct* secret shares to each party

        DataToSend::Private(self.shares.0.clone())
    }

    fn should_delay(&self, m: &KeygenData) -> bool {
        matches!(m, KeygenData::Complaints4(_))
    }

    fn process(
        self,
        incoming_shares: HashMap<usize, Option<Self::Message>>,
    ) -> StageResult<KeygenData, KeygenResultInfo> {
        // As the messages for this stage are sent in secret, it is possible
        // for a malicious party to send us invalid data (or not send anything
        // at all) without us being able to prove that. Because of that, we
        // can't simply terminate our protocol here.

        let mut bad_parties = vec![];
        let verified_shares: HashMap<usize, Self::Message> = incoming_shares
            .into_iter()
            .filter_map(|(sender_idx, share_opt)| {
                if let Some(share) = share_opt {
                    if verify_share(&share, &self.commitments[&sender_idx], self.common.own_idx) {
                        Some((sender_idx, share))
                    } else {
                        slog::warn!(
                            self.common.logger,
                            "Received invalid secret share from party: {}",
                            sender_idx
                        );

                        bad_parties.push(sender_idx);
                        None
                    }
                } else {
                    slog::warn!(
                        self.common.logger,
                        "Received no secret share from party: {}",
                        sender_idx
                    );

                    bad_parties.push(sender_idx);
                    None
                }
            })
            .collect();

        let processor = ComplaintsStage4 {
            common: self.common.clone(),
            commitments: self.commitments,
            shares: IncomingShares(verified_shares),
            outgoing_shares: self.shares,
            complaints: bad_parties,
        };
        let stage = BroadcastStage::new(processor, self.common);

        StageResult::NextStage(Box::new(stage))
    }
}

/// During this stage parties have a chance to complain about
/// a party sending a secret share that isn't valid when checked
/// against the commitments
struct ComplaintsStage4 {
    common: CeremonyCommon,
    // commitments (verified to have been broadcast correctly)
    commitments: HashMap<usize, DKGCommitment>,
    /// Shares sent to us from other parties (secret)
    shares: IncomingShares,
    outgoing_shares: OutgoingShares,
    complaints: Vec<usize>,
}

derive_display_as_type_name!(ComplaintsStage4);

impl BroadcastStageProcessor<KeygenData, KeygenResultInfo> for ComplaintsStage4 {
    type Message = Complaints4;

    fn init(&mut self) -> DataToSend<Self::Message> {
        DataToSend::Broadcast(Complaints4(self.complaints.clone()))
    }

    fn should_delay(&self, m: &KeygenData) -> bool {
        matches!(m, KeygenData::VerifyComplaints5(_))
    }

    fn process(
        self,
        messages: HashMap<usize, Option<Self::Message>>,
    ) -> StageResult<KeygenData, KeygenResultInfo> {
        let processor = VerifyComplaintsBroadcastStage5 {
            common: self.common.clone(),
            received_complaints: messages,
            commitments: self.commitments,
            shares: self.shares,
            outgoing_shares: self.outgoing_shares,
        };

        let stage = BroadcastStage::new(processor, self.common);

        StageResult::NextStage(Box::new(stage))
    }
}

struct VerifyComplaintsBroadcastStage5 {
    common: CeremonyCommon,
    received_complaints: HashMap<usize, Option<Complaints4>>,
    commitments: HashMap<usize, DKGCommitment>,
    shares: IncomingShares,
    outgoing_shares: OutgoingShares,
}

derive_display_as_type_name!(VerifyComplaintsBroadcastStage5);

impl BroadcastStageProcessor<KeygenData, KeygenResultInfo> for VerifyComplaintsBroadcastStage5 {
    type Message = VerifyComplaints5;

    fn init(&mut self) -> DataToSend<Self::Message> {
        let data = self.received_complaints.clone();

        DataToSend::Broadcast(VerifyComplaints5 { data })
    }

    fn should_delay(&self, data: &KeygenData) -> bool {
        matches!(data, KeygenData::BlameResponse6(_))
    }

    fn process(
        self,
        messages: HashMap<usize, Option<Self::Message>>,
    ) -> StageResult<KeygenData, KeygenResultInfo> {
        let verified_complaints = match verify_broadcasts(messages, &self.common.logger) {
            Ok(comms) => comms,
            Err(blamed_parties) => {
                return StageResult::Error(
                    blamed_parties,
                    anyhow::Error::msg("Inconsistent broadcast of complaints"),
                );
            }
        };

        if verified_complaints.iter().all(|(_idx, c)| c.0.is_empty()) {
            // if all complaints are empty, we can finalize the ceremony
            let keygen_result_info =
                compute_keygen_result_info(self.common, self.shares, &self.commitments);

            return StageResult::Done(keygen_result_info);
        };

        // Some complaints have been issued, entering the blaming stage

        let idxs_to_report: Vec<_> = verified_complaints
            .iter()
            .filter_map(|(idx_from, Complaints4(blamed_idxs))| {
                // Ensure that complaints contain valid, non-duplicate indexes
                let deduped_idxs = {
                    let mut idxs = blamed_idxs.clone();
                    idxs.sort_unstable();
                    idxs.dedup();
                    idxs
                };

                let has_duplicates = deduped_idxs.len() != blamed_idxs.len();

                if has_duplicates {
                    slog::warn!(
                        self.common.logger,
                        "Complaint had duplicates: {}",
                        format_iterator(blamed_idxs)
                    );
                }

                let has_invalid_idxs = !blamed_idxs.iter().all(|idx_blamed| {
                    if self.common.is_idx_valid(*idx_blamed) {
                        true
                    } else {
                        slog::warn!(
                            self.common.logger,
                            "Invalid index in complaint: {}",
                            format_iterator(blamed_idxs)
                        );
                        false
                    }
                });

                if has_duplicates || has_invalid_idxs {
                    Some(*idx_from)
                } else {
                    None
                }
            })
            .collect();

        if idxs_to_report.is_empty() {
            let processor = BlameResponsesStage6 {
                common: self.common.clone(),
                complaints: verified_complaints,
                shares: self.shares,
                outgoing_shares: self.outgoing_shares,
                commitments: self.commitments,
            };

            let stage = BroadcastStage::new(processor, self.common);

            StageResult::NextStage(Box::new(stage))
        } else {
            StageResult::Error(idxs_to_report, anyhow::Error::msg("Improper complaint"))
        }
    }
}

fn compute_keygen_result_info(
    common: CeremonyCommon,
    secret_shares: IncomingShares,
    commitments: &HashMap<usize, DKGCommitment>,
) -> KeygenResultInfo {
    let share_count = common.all_idxs.len();

    let key_share = secret_shares
        .0
        .values()
        .into_iter()
        .map(|share| share.value.clone())
        .sum();

    // The shares are no longer needed so we zeroize them
    drop(secret_shares);

    let agg_pubkey = derive_aggregate_pubkey(commitments);

    let params = ThresholdParameters::from_share_count(share_count);

    let party_public_keys = derive_local_pubkeys_for_parties(params, commitments);

    KeygenResultInfo {
        params: ThresholdParameters::from_share_count(party_public_keys.len()),
        key: Arc::new(KeygenResult {
            key_share: KeyShare {
                y: agg_pubkey,
                x_i: key_share,
            },
            party_public_keys,
        }),
        validator_map: common.validator_mapping,
    }
}

struct BlameResponsesStage6 {
    common: CeremonyCommon,
    complaints: HashMap<usize, Complaints4>,
    shares: IncomingShares,
    outgoing_shares: OutgoingShares,
    commitments: HashMap<usize, DKGCommitment>,
}

derive_display_as_type_name!(BlameResponsesStage6);

impl BroadcastStageProcessor<KeygenData, KeygenResultInfo> for BlameResponsesStage6 {
    type Message = BlameResponse6;

    fn init(&mut self) -> DataToSend<Self::Message> {
        // Indexes at which to reveal/broadcast secret shares
        let idxs_to_reveal: Vec<_> = self
            .complaints
            .iter()
            .filter_map(|(idx, complaint)| {
                if complaint.0.contains(&self.common.own_idx) {
                    slog::warn!(
                        self.common.logger,
                        "[{}] we are blamed by [{}]",
                        self.common.own_idx,
                        idx
                    );

                    Some(*idx)
                } else {
                    None
                }
            })
            .collect();

        // TODO: put a limit on how many shares to reveal?
        let data = DataToSend::Broadcast(BlameResponse6(
            idxs_to_reveal
                .iter()
                .map(|idx| {
                    slog::debug!(self.common.logger, "revealing share for [{}]", *idx);
                    (*idx, self.outgoing_shares.0[idx].clone())
                })
                .collect(),
        ));

        // Outgoing shares are no longer needed, so we zeroize them
        drop(std::mem::take(&mut self.outgoing_shares));

        data
    }

    fn should_delay(&self, data: &KeygenData) -> bool {
        matches!(data, KeygenData::VerifyBlameResponses7(_))
    }

    fn process(
        self,
        blame_responses: HashMap<usize, Option<Self::Message>>,
    ) -> StageResult<KeygenData, KeygenResultInfo> {
        let processor = VerifyBlameResponsesBroadcastStage7 {
            common: self.common.clone(),
            complaints: self.complaints,
            blame_responses,
            shares: self.shares,
            commitments: self.commitments,
        };

        let stage = BroadcastStage::new(processor, self.common);

        StageResult::NextStage(Box::new(stage))
    }
}

struct VerifyBlameResponsesBroadcastStage7 {
    common: CeremonyCommon,
    complaints: HashMap<usize, Complaints4>,
    // Blame responses received from other parties in the previous communication round
    blame_responses: HashMap<usize, Option<BlameResponse6>>,
    shares: IncomingShares,
    commitments: HashMap<usize, DKGCommitment>,
}

derive_display_as_type_name!(VerifyBlameResponsesBroadcastStage7);

fn derive_expected_blame_response_indexes(
    complaints: &HashMap<usize, Complaints4>,
) -> HashMap<usize, BTreeSet<usize>> {
    let mut expected: HashMap<usize, BTreeSet<usize>> = HashMap::new();

    for (blamer_idx, Complaints4(blamed_idxs)) in complaints {
        for blamed_idx in blamed_idxs {
            expected.entry(*blamed_idx).or_default().insert(*blamer_idx);
        }
    }

    expected
}

/// Checks if the blame response contains all (and only) expected indexes
fn is_blame_response_complete(
    response: &BlameResponse6,
    expected_share_idxs: &BTreeSet<usize>,
) -> bool {
    // BTreeSet<T> is just a BTreeMap<T, ()>, so the elements
    // are expected to be in the same order
    response.0.keys().into_iter().eq(expected_share_idxs.iter())
}

#[cfg(test)]
#[test]
fn test_derive_expected_blame_response_indexes() {
    use std::iter::FromIterator;

    let complaints: HashMap<usize, Complaints4> = [
        (1, Complaints4(vec![])),
        (2, Complaints4(vec![1, 3])),
        (3, Complaints4(vec![1])),
    ]
    .iter()
    .cloned()
    .collect();

    let expected: HashMap<usize, BTreeSet<usize>> = {
        let set1 = BTreeSet::from_iter([2, 3].iter().copied());
        let set2 = BTreeSet::from_iter([2].iter().copied());
        [(1, set1), (3, set2)].iter().cloned().collect()
    };

    assert_eq!(
        derive_expected_blame_response_indexes(&complaints),
        expected
    );
}

impl VerifyBlameResponsesBroadcastStage7 {
    /// Check that blame responses contain all (and only) the requested shares, and that all the shares are valid.
    /// If all responses are valid, returns shares destined for us along with the corresponding index. Otherwise,
    /// returns a list of party indexes who provided invalid responses.
    fn check_blame_responses(
        &self,
        blame_responses: HashMap<usize, BlameResponse6>,
    ) -> Result<HashMap<usize, ShamirShare>, Vec<usize>> {
        // For each party, the indexes as which secret shares
        // should be revealed
        let mut expected_blame_responses = derive_expected_blame_response_indexes(&self.complaints);

        let mut shares_for_us = HashMap::<usize, ShamirShare>::new();
        let mut bad_parties = vec![];

        'sender: for (sender_idx, response) in blame_responses {
            // Check that indexes in responses match those in complaints

            // Note: for parties who weren't blamed we will get an empty vec,
            // and check that the response is also empty
            let expected_idxs = expected_blame_responses
                .remove(&sender_idx)
                .unwrap_or_default();

            if !is_blame_response_complete(&response, &expected_idxs) {
                bad_parties.push(sender_idx);
                continue;
            }

            for (dest_idx, share) in response.0 {
                let commitment = &self.commitments[&sender_idx];

                if verify_share(&share, commitment, dest_idx) {
                    // if the share is meant for us, save it
                    if dest_idx == self.common.own_idx {
                        shares_for_us.insert(sender_idx, share);
                    }
                } else {
                    slog::warn!(
                        self.common.logger,
                        "Invalid secret share in a blame response from party: {}",
                        sender_idx
                    );

                    bad_parties.push(sender_idx);
                    // No reason to look at any other share from this sender
                    continue 'sender;
                }
            }
        }

        if bad_parties.is_empty() {
            Ok(shares_for_us)
        } else {
            Err(bad_parties)
        }
    }
}

impl BroadcastStageProcessor<KeygenData, KeygenResultInfo> for VerifyBlameResponsesBroadcastStage7 {
    type Message = VerifyBlameResponses7;

    fn init(&mut self) -> DataToSend<Self::Message> {
        let data = self.blame_responses.clone();

        DataToSend::Broadcast(VerifyBlameResponses7 { data })
    }

    fn should_delay(&self, _: &KeygenData) -> bool {
        false
    }

    fn process(
        mut self,
        messages: HashMap<usize, Option<Self::Message>>,
    ) -> StageResult<KeygenData, KeygenResultInfo> {
        slog::debug!(
            self.common.logger,
            "Processing verifications for blame responses"
        );

        let verified_responses = match verify_broadcasts(messages, &self.common.logger) {
            Ok(comms) => comms,
            Err(blamed_parties) => {
                return StageResult::Error(
                    blamed_parties,
                    anyhow::Error::msg("Inconsistent broadcast of blame response"),
                );
            }
        };

        match self.check_blame_responses(verified_responses) {
            Ok(shares_for_us) => {
                for (sender_idx, share) in shares_for_us {
                    self.shares.0.insert(sender_idx, share);
                }

                let keygen_result_info =
                    compute_keygen_result_info(self.common, self.shares, &self.commitments);

                StageResult::Done(keygen_result_info)
            }
            Err(bad_parties) => StageResult::Error(
                bad_parties,
                anyhow::Error::msg("Invalid secret share in a blame response"),
            ),
        }
    }
}
